\documentclass[10pt,journal,compsoc]{IEEEtran}

% *** CITATION PACKAGES ***
\ifCLASSOPTIONcompsoc
  \usepackage[nocompress]{cite}
\else
  \usepackage{cite}
\fi

% *** GRAPHICS ***
\ifCLASSINFOpdf
   \usepackage[pdftex]{graphicx}
\else
   \usepackage[dvips]{graphicx}
\fi
\usepackage{amsmath}
\usepackage{algorithm}
\usepackage{algorithmic}
\usepackage{array}
\usepackage{mdwmath}
\usepackage{mdwtab}
\usepackage{eqparbox}
% Subfig package (OK)

\ifCLASSOPTIONcompsoc
  \usepackage[caption=false,font=footnotesize,labelfont=sf,textfont=sf]{subfig}
\else
  \usepackage[caption=false,font=footnotesize]{subfig}
\fi
\usepackage{url}
\usepackage[hidelinks]{hyperref}
\hyphenation{op-tical net-works semi-conduc-tor}

\begin{document}

\title{Is this edible? A machine Learning Project}

\author{Gabriele~Maria~Morello - Polina~Kireeva}

\begin{IEEEkeywords}

Machine Learning, Mushroom, Edible.

\end{IEEEkeywords}

\maketitle

\ifCLASSOPTIONcompsoc
\IEEEraisesectionheading{\section{Introduction}\label{sec:introduction}}
\else
\section{Introduction}
\label{sec:introduction}
\fi

\IEEEPARstart {T}he Machine Learning Assignment focused on the classification of mushrooms using a dataset with information about 61069 hypothetical mushrooms based on 173 species and classified as edible, poisonous or no information about edibility.\\

The dataset used for the assignment is called “Secondary Mushroom Dataset" and it is derived from the one with empirical data about different variety of mushrooms.\\ 

The original dataset was not considered for the assignment because it did not allow various forms of pre-processing (e.g. imputation of missing values) and it contained too few variables (173 entries) to be used for training of the machine learning algorithm.\\

The dataset used for the assignment is available at:\url{https://archive.ics.uci.edu/dataset/848/secondary+mushroom+dataset}.\\

The assignment group is composed of the members:

\begin{itemize}

  \item Gabriele Maria Morello;\\
  
  \item Polina Kireeva.

\end{itemize}

The activities were done following the structure of the Machine Learning course covering all the topics to simplify the final evaluation process.\\

All members were directily involved in defining and reviewing all the section of the machine learning assignment providing meaningful feedback or adjustments to the analysis performed.\\

The group organization was structured without a rigid separation of tasks regarding sections, the idea was to adopt an agile approach with an iterative process over modular sections.\\ 

The member Kireeva supervised the definition of the problem and evaluated possible algorithm to be implemented.\\

The problem was to find a suitable dataset that could offer possibility of pre-processing and provide analysis opportunity to cover almost all the CRISP-DM cycle.\\

The member Morello searched a dataset suitable for the assignment and reviewed existing paper covering the topics of Machine Learning in mushroom classification (more details in the next section).\\ 

The Data understanding, Modeling and Evaluation sections cannot be attributed to a specific member because these tasks required a cooperative approach to discuss which procedures will provide the best results regarding the machine learning assignment.\\
 
\hfill November 25, 2025

\section{Related Work}

There were three papers analyzed to evaluate different types of methodologies and approaches to obtain useful insights for the Machine Learning assignment. The articles are:

\begin{itemize}

  \item “Mushroom data creation, curation, and simulation to support classification tasks'' available at:\url{https://www.nature.com/articles/s41598-021-87602-3};\\
  
  \item “A Comparative Study of Machine Learning Methods for Optimizing Mushroom Classification'', can be read here:\url{https://www.jcbi.org/index.php/Main/article/view/726};\\
  
  \item “IoT enabled mushroom farm automation with Machine Learning to classify toxic mushrooms in Bangladesh'' available at the link:\url{https://www.sciencedirect.com/science/article/pii/S2666154321001691};\\
  
\end{itemize}

The first paper analyzes topics that overlap with the assignment and could be useful to evaluate different approach and future improvements.\\ 

Regarding data curation, an interesting insight provided is how the way data is collected can influence the choice of the algorithm (e.g. image or attributes based).\\

This also reflects on the dataset used for the algorithm training, the paper analyzed the original dataset and created a secondary one with increased number of entries while still remained balanced regarding the edibitily to poisonous ratio.\\ 

It may seem an obvious conclusion but having agency over the data collection choices can produce effects on the overall cost (economic and time) of the entire process.\\

Regarding data quality and integrity there was a similar thought process regarding correlation analysis to remove reduntant variables.\\ 

For algorithm use, the paper evaluated five different classifiers for the predictive models with metrics like accuracy and F2 score (prioritize recall over precision) and then compared to the original dataset.\\

This is beyond the scope of the assignment but it provides an interesting take on the usage of more fine-tuned metrics to evaluate the training of the machine learning algorithm, so it was considered useful for the assignment purpose.\\

The second paper is focused on models comparison, the ones considered are:

\begin{itemize}

  \item Random Forest;\\

  \item Gradient Boosting Machines (GBMS) a consecutive input strategy addressing mistakes of the past models by training weak learners (e.g. shallow decision trees) in a gradient descent framework;\\

  \item Ada Boost (Adaptive Boosting), consolidating a succession of feeble classifiers and changing their weight at every iteration to adjust errors. The last classifier is a weighted mix the previous ones, giving weight to the best performing on training data;\\

  \item Extra Trees (Extremely Randomized Trees) an ensemble technique similar to Random Forest but arbitrarely (without usage of Gini or data gain);\\

  \item Bagging (Bootstrap Aggregating).\\

\end{itemize}

The metrics used were: accuracy, precision, recall, F1 Score, ROC AUC (probability of higher random Positi than random Negative cases), Matthews Correlation Coefficient (showing nature of binary classifications) and Cohen's Kappa (measurement arrangement between two raters ordering into unrelated categories).\\

The main take from this paper is the use of different models to evaluate their effectiveness by using different parameters for comparison. It provides a theoretical ground for evaluating new possible models for the assignent and new metrics to evaluate the performance of the models.\\

The last paper also evaluates different types of models but the main point for the assignment is the evaluation of FP and FN. It is important to properly assess it because in the case of mushroom classification a FP can cause problem to health and safety, especially when deployed by an agricultural company.\\

Multiple parameters were used to account for the need to have a precise assessment on how correct the predictions on edible mushrooms are.\\

Another interesting analysis regards execution time. It is beyond the scope of the assignment but should be evaluated when handling projects that process enormous amounts of data. It should be important to evaluate pros and cons between better performing models and their precision.\\

\section{Proposed Method}

The dataset (Secondary Mushroom dataset) had a problem regarding data visualization, the source of it was found in a delimiter error in the .csv file because instead of displaying a comma a selicolomn was used.\\

The dataset was analyzed in a tabular form to have a general overview of the data. It originally contained 21 features and 61069 observation with two data types of “object" and “float64".\\ 

The data understanding phase helped evaluate the presence of null values for each feature and their predominance over the total entries.\\

Then an evaluation was done to drop all the features with high null values and “stem-root", “veil-type", “veil-color", “spore-print-color" and “stem-surface" were dropped.\\

For the features “gill-spacing", “cap-surface", “ring-type" and “gill-attachment" the use of imputation was attempted, performing a grafical analysis to evaluate how frequently the entries occurred for each feature.\\ 

The possibility of mean imputation was considered but the high amount of missing entries led to dropping them.\\  

The features “cap-shape", “cap-color", “gill-color", “stem-color", “habitat" and “season" had their values represented as letters and the use of encoding was needed, since most algorithms only support numerical values.\\ 

Simply mapping the letters as numbers could mislead some algorithms to see the values as a scale, which is not true in this case of colors, seasons, shapes and habitats, so the one-hot encoding was chosen as the appropriate approach for this assignment.\\ 

However, applying it to all 6 features increased the amount of features to 51, more than double compared to the original ones (an increase of 30 from the initial 21). This amount will, however, be later reduced to simplify computations and save resourses.\\

The numerical features “cap-diameter", “stem-height" and “stem-width" had values using different scales (0.38 to 62.34, 0.0 to 33.92 and 0.0 to 103.91), so they were all normalized to a scale of 0 to 1.\\

The next step was the creation of a correlation matrix, which would help identify redundant features - if any two or more features were highly correlated, that would mean having both present would not be highly beneficial for the model's accuracy.\\

A correlation matrix heatmap was used for a visual representation of the level of correlation between all features, then a filter was applied so only highly correlated (both positive and negative correlation) features would be displayed for clarity.\\ 

The features “season\_a\_encoded" and “season\_u\_encoded" showed a correlation of over 0.75. This was considered the threshold to considered features highly correlated and so “season\_a\_encoded" was discarded.\\

This concluded the data understanding phase. All the previous step were done to ensure a proper set of data that could be used to train the machine learning algorithm.\\

The next phase was modeling the data, the first step consisted in splitting them between training sets (data from which the model would find a pattern) and test sets used to verify how the model would perform.\\

After the splitting has been completed, it was considered the tree classifieras a possible algorithm with an accuracy score to evaluate the model how well the model is able to correctly predict edible mushrooms.\\

In addition to the accuracy score, a graphical representation on how the accuracy changes based on the depht of the decision tree was done.\\ 

Also, a feature importance was attempted to see if all all the feature selected were relevant in the modeling of the algorithm.\\

To verify the assumption of the algorith chosen a random forest classified was deploy to evaluate the difference in accuracy.\\

Lastly, AutoML was used to evaluate the best models and hyperparameters for the Secondary mushroom dataset.\\

\section{Results}

The results of the assignment regards different type of algorithm used, their accuracy and an AutoML analysis to verify the existance of better algorithms.\\

A shallow decision tree with a maximum depth of 2 was used to see the baseline accuracy of a simple model, which was 0.63. Then decision trees were trained with increasing depth and the results were displayed in a graph.\\ 

The graph showed a significant decrease in accuracy gain after the depth of 13, and a plateau after 16. A desicion tree with the depth of 13 showed accuracy of 0.92.\\

Since the decision tree showed good results, it was decided to apply a more complex algorithm of the same type - the random forest. The accuracy achieved was 0.996 (rounded up for simplicity).\\

Then, in an attempt to push the efficiently achieved accuracy even further, AutoML was used. With a time budget of 60 seconds, the best algorithm was determined to be XGBClassifier with the accuracy of 0.996 (rounded up for simplicity).\\

Considering the relatively large number of features, feature importances were evaluated - the ones with a 0 value for the deeper decision tree were removed.\\ 

As a result, the decision trees' accuracies didn't change and the AutoML result showed a tiny accuracy improvement (approximately 0.0004).\\

As for the random forest, a tiny drop in accuracy was observed (approximately 0.00008) - this is insignificant, as such changes could be attributed to the randomness of the random forest - meaning, with a different seed the difference could have been reverse.\\ 

Feature importance for random forest was also reviewed to make sure the 10 removed features did not hold much importance to the algorithm, and they did not: the one with the highest importance out of the removed ones had 0.0026 (less than 1\%).\\ 

Since no considerable negative results were observed, the removal was kept to simplify computations.\\

\section{Conclusion}

This is the conclusion.

\begin{thebibliography}{1}

\bibitem{IEEEhowto:kopka}

This is the bibliography.

\end{thebibliography}

\end{document}
